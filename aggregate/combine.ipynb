{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and Clean Data Sources\n",
    "\n",
    "This notbook is used to combine all data in to a single Sqlite database. The cleaning evolved heavily so at some point, all this cleaning should be refactored into a seperate module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import gettext\n",
    "\n",
    "from cleantext import clean\n",
    "import dataset\n",
    "import requests\n",
    "import pycountry\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = gettext.translation(\"iso3166\", pycountry.LOCALES_DIR, languages=[\"de\"])\n",
    "german.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Fixes\n",
    "\n",
    "There are sometimes errors in the data. Since each incident has a uniquie id, fix it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_fixes = {\n",
    "    \"ca0dee4be1029c2ab24cdea755b88086\": {\"city\": \"Halle (Saale)\"},\n",
    "    \"https://www.raa-sachsen.de/support/chronik/vorfaelle/bon-courage-fassungslos-ueber-naziuebergriffe-auf-dem-bornaer-stadtfest-3219\": {\n",
    "        \"city\": \"Borna\"\n",
    "    },\n",
    "    \"mobile-beratung-a10d62daa23594df92c9704e1606dcfc\": {\n",
    "        \"city\": \"Oranienbaum-WÃ¶rlitz\",\n",
    "        \"county\": \"Wittenberg\",\n",
    "    },\n",
    "    \"mobile-beratung-000dad6aace24b3d8ebae940a8de8e72\": {\"city\": \"Dessau\"},\n",
    "    \"https://www.raa-sachsen.de/support/chronik/vorfaelle/goerlitz-2779\": {\n",
    "        \"date\": date(2010, 11, 14)\n",
    "    },\n",
    "    \"https://www.raa-sachsen.de/support/chronik/vorfaelle/leipzig-reudnitz-4976\": {\n",
    "        \"date\": date(2020, 11, 13)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Regions\n",
    "\n",
    "Taken regions.json from <https://github.com/datenguide/metadata>\n",
    "\n",
    "These files contains a list of all valid regios. If a region is not in there, filter it out. This greatly the performance of the geocoding api. It's not optimal that we acutlaly throw this information await. This information should be kept actually. (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"regions.json\") as json_file:\n",
    "    regions = json.load(json_file)\n",
    "\n",
    "regions = list(regions.values())\n",
    "regions_counties = [x for x in regions if x[\"level\"] == 3]\n",
    "\n",
    "\n",
    "def is_valid_county(county):\n",
    "    return (\n",
    "        len(\n",
    "            [\n",
    "                x\n",
    "                for x in regions_counties\n",
    "                if x[\"name\"].startswith(county)\n",
    "                and x[\"duration\"][\"until\"] == \"2019-12-31T00:00:00.000Z\"\n",
    "            ]\n",
    "        )\n",
    "        != 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read it some secrets later needed to comunicate with an internal API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tuple(Path(\"secrets.txt\").read_text().split()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_incidents = []\n",
    "all_src = []\n",
    "all_chronicle = []\n",
    "\n",
    "for p in Path(\"data\").glob(\"*.db\"):\n",
    "    print(p)\n",
    "    db = dataset.connect(\"sqlite:///\" + str(p))\n",
    "    all_incidents += db[\"incidents\"].all()\n",
    "    all_src += db[\"sources\"].all()\n",
    "\n",
    "    new_chro = list(db[\"chronicle\"].all())\n",
    "    if len(new_chro) == 0:\n",
    "        new_chro = db[\"chronicles\"].all()\n",
    "\n",
    "    all_chronicle += new_chro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in all_chronicle:\n",
    "    if \"region\" in x and len(x[\"region\"]) > 0:\n",
    "        continue\n",
    "    if \"iso3166_2\" in x and x[\"iso3166_2\"] != None and len(x[\"iso3166_2\"]) > 0:\n",
    "        x[\"region\"] = pycountry.subdivisions.get(code=x[\"iso3166_2\"]).name\n",
    "    elif \"iso3166_1\" in x and x[\"iso3166_1\"] != None and len(x[\"iso3166_1\"]) > 0:\n",
    "        x[\"region\"] = pycountry.countries.get(alpha_2=x[\"iso3166_1\"]).name\n",
    "    else:\n",
    "        raise ValueError(\"Need to specify region somehow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using date (and without time (hour/minute)) for now\n",
    "\n",
    "\n",
    "def ensure_date(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    if isinstance(x, datetime):\n",
    "        return x.date()\n",
    "    elif isinstance(x, date):\n",
    "        return x\n",
    "    ValueError(\"neither date or datetime\")\n",
    "\n",
    "\n",
    "for row in all_src:\n",
    "    if \"date\" in row:\n",
    "        row[\"date\"] = ensure_date(row[\"date\"])\n",
    "    else:\n",
    "        row[\"date\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dataset.connect(\"sqlite:///rechtegewalt.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_incidents = db[\"incidents\"]\n",
    "for x in all_incidents:\n",
    "    if \"id\" in x:\n",
    "        x.pop(\"id\")\n",
    "tab_incidents.insert_many(all_incidents)\n",
    "\n",
    "tab_src = db[\"sources\"]\n",
    "for x in all_src:\n",
    "    if \"id\" in x:\n",
    "        x.pop(\"id\")\n",
    "tab_src.insert_many(all_src)\n",
    "\n",
    "tab_chro = db[\"chronicles\"]\n",
    "for x in all_chronicle:\n",
    "    if \"id\" in x:\n",
    "        x.pop(\"id\")\n",
    "tab_chro.insert_many(all_chronicle)\n",
    "\n",
    "tab_incidents.create_index([\"rg_id\"])\n",
    "tab_src.create_index([\"rg_id\"])\n",
    "\n",
    "# tab_incidents.create_index([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_state_country(row):\n",
    "    chro = tab_chro.find_one(chronicler_name=row[\"chronicler_name\"])\n",
    "    if not \"iso3166_2\" in chro or chro[\"iso3166_2\"] is None:\n",
    "        row[\"country\"] = \"Deutschland\"\n",
    "        return row\n",
    "\n",
    "    sub = pycountry.subdivisions.get(code=chro[\"iso3166_2\"])\n",
    "    assert sub is not None\n",
    "    row[\"state\"] = sub.name\n",
    "    row[\"country\"] = _(sub.country.name)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_words = [\"Landkreis\", \"Landkeis\", \"Kreis\", \"LK\"]\n",
    "\n",
    "\n",
    "def clean_county(x):\n",
    "    if x is None or x == \"None\":\n",
    "        return None\n",
    "    x = clean_string(x)\n",
    "\n",
    "    for w in county_words:\n",
    "        w += \" \"\n",
    "        if x.startswith(w):\n",
    "            x = x[len(w) :]\n",
    "\n",
    "    if not is_valid_county(x):\n",
    "        print(\"removing\", x)\n",
    "        return None\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_city(x):\n",
    "    x = clean_string(x)\n",
    "    if x is None:\n",
    "        return None\n",
    "    assert len(x) > 0\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_string(x):\n",
    "    x = clean(x, lang=\"de\", lower=False)\n",
    "    if len(x) == 0:\n",
    "        return None\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_county():\n",
    "    statement = \"SELECT * FROM incidents GROUP BY city, state having count(*) > 1\"\n",
    "    for row in db.query(statement):\n",
    "        dupli = list(tab_incidents.find(city=row[\"city\"], state=row[\"state\"]))\n",
    "        county_can = []\n",
    "        contains_none = False\n",
    "        for d in dupli:\n",
    "            if d[\"county\"] is not None:\n",
    "                county_can.append(d[\"county\"])\n",
    "            else:\n",
    "                contains_none = True\n",
    "\n",
    "        unique_can = list(set(county_can))\n",
    "        if contains_none and len(unique_can) == 1:\n",
    "            tab_incidents.update(\n",
    "                {\"city\": row[\"city\"], \"county\": unique_can[0]}, [\"city\"]\n",
    "            )\n",
    "            print(unique_can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean location text because there were still some errors\n",
    "for x in tqdm(tab_incidents.all()):\n",
    "    if x[\"rg_id\"] in manual_fixes:\n",
    "        x = {**x, **manual_fixes[x[\"rg_id\"]]}\n",
    "\n",
    "    if not \"county\" in x:\n",
    "        no_county = True\n",
    "        x[\"county\"] = None\n",
    "\n",
    "    x[\"county\"] = x[\"orig_county\"] = clean_string(x[\"county\"])\n",
    "    x[\"city\"] = x[\"orig_city\"] = clean_string(x[\"city\"])\n",
    "\n",
    "    if \"address\" in x and x[\"address\"] is not None:\n",
    "        x[\"address\"] = x[\"orig_address\"] = clean_string(x[\"address\"])\n",
    "\n",
    "    x = add_state_country(x)\n",
    "\n",
    "    if x[\"date\"] is None:\n",
    "        print(\"date is broken, skipping\")\n",
    "        print(x)\n",
    "        tab_incidents.delete(id=x[\"id\"])\n",
    "        continue\n",
    "    #         raise ValueError\n",
    "\n",
    "    # ignore older data\n",
    "    if x[\"date\"].year < 2000:\n",
    "        tab_incidents.delete(id=x[\"id\"])\n",
    "\n",
    "    x[\"date\"] = ensure_date(x[\"date\"])\n",
    "\n",
    "    #   manual fix\n",
    "    if x[\"city\"] == \"Zerbst\" and x[\"state\"] == \"Sachsen-Anhalt\":\n",
    "        x[\"city\"] = \"Zerbst/Anhalt\"\n",
    "\n",
    "    tab_incidents.update(x, [\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill_missing_county()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_all():\n",
    "    tab_incidents.create_column(\"district\", db.types.text)\n",
    "    if \"address\" not in tab_incidents.columns:\n",
    "        tab_incidents.create_column(\"address\", db.types.text)\n",
    "    if \"state\" not in tab_incidents.columns:\n",
    "        tab_incidents.create_column(\"state\", db.types.text)\n",
    "    if \"longitude\" not in tab_incidents.columns:\n",
    "        tab_incidents.create_column(\"longitude\", db.types.float)\n",
    "    if \"latitude\" not in tab_incidents.columns:\n",
    "        tab_incidents.create_column(\"latitude\", db.types.float)\n",
    "    statement = (\n",
    "        \"SELECT DISTINCT address, city, district, county, state, country FROM incidents\"\n",
    "    )\n",
    "    subs = list(db.query(statement))\n",
    "\n",
    "    # the geocoding api has problems with Leipzig as County. (There is a Landkreis Leipzig and a seperate City Leipzig)\n",
    "    removed_counties_with_ids = []\n",
    "    for i, x in enumerate(subs):\n",
    "        if x[\"state\"] is None:\n",
    "            print(x)\n",
    "        if x[\"county\"] == \"Leipzig\":\n",
    "            removed_county = x.pop(\"county\")\n",
    "            x[\"county\"] = None\n",
    "            removed_counties_with_ids.append([removed_county, i])\n",
    "\n",
    "    r = requests.post(\n",
    "        \"https://geocode.app.vis.one/\",\n",
    "        auth=auth,\n",
    "        json={\"provider\": \"here\", \"locations\": [{\"query\": dict(x)} for x in subs]},\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    subs_location = r.json()[\"locations\"]\n",
    "\n",
    "    # add back county since it was correct\n",
    "    for x, i in removed_counties_with_ids:\n",
    "        subs_location[i][\"query\"][\"county\"] = x\n",
    "\n",
    "    return subs_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_location = geocode_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_second(subs_location):\n",
    "    second_check = []\n",
    "    second_check_ids = []\n",
    "\n",
    "    for i, x in enumerate(subs_location):\n",
    "        if len(x) == 1 and \"county\" in x[\"query\"] and x[\"query\"][\"county\"] is not None:\n",
    "            x[\"query\"][\"city\"] = x[\"query\"][\"city\"] + \", \" + x[\"query\"][\"county\"]\n",
    "            x[\"query\"][\"county\"] = None\n",
    "            second_check.append(x)\n",
    "            second_check_ids.append(i)\n",
    "\n",
    "    print(len(second_check))\n",
    "    if len(second_check) == 0:\n",
    "        return subs_location\n",
    "    r = requests.post(\n",
    "        \"https://geocode.app.vis.one/\",\n",
    "        auth=auth,\n",
    "        json={\n",
    "            \"provider\": \"here\",\n",
    "            \"locations\": [{\"query\": x[\"query\"]} for x in second_check],\n",
    "        },\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "\n",
    "    for i, x in enumerate(r.json()[\"locations\"]):\n",
    "        if len(x) != 1:\n",
    "            subs_location[second_check_ids[i]] = x\n",
    "            print(\"found!\", x)\n",
    "    return subs_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used right now?\n",
    "# subs_location = geocode_second(subs_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_locations = []\n",
    "\n",
    "for x in subs_location:\n",
    "    if len(x) == 1:\n",
    "        #         could not geocode these locations\n",
    "        print(\"error here, deleting for now\", x)\n",
    "    #         tab_incidents.delete(**x['query'])\n",
    "    else:\n",
    "        #         rename\n",
    "        query = x.pop(\"query\")\n",
    "        x[\"query_county\"] = query[\"county\"]\n",
    "        x[\"query_city\"] = query[\"city\"]\n",
    "        x[\"query_address\"] = query[\"address\"]\n",
    "        good_locations.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_loc = db[\"locations\"]\n",
    "tab_loc.insert_many(good_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_loc.create_index([\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Locations\n",
    "\n",
    "We are trying out several ways to merge the location with geolocation back to the old without. Since we maniputlated the county etc., we have to try varioous ways how to merge. This should get improved (TDOO)\n",
    "\n",
    "\n",
    "Not really sure whether a seperate table for location is needed. It was introduced because in some cases, multiple locations are associated with incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(tab_incidents.all()):\n",
    "    real_lat, real_long = x[\"latitude\"], x[\"longitude\"]\n",
    "    x_query = {name: x[name] for name in [\"state\", \"country\"]}\n",
    "    row_loc = tab_loc.find_one(\n",
    "        query_county=x[\"orig_county\"],\n",
    "        query_city=x[\"orig_city\"],\n",
    "        query_address=x[\"address\"],\n",
    "        **x_query\n",
    "    )\n",
    "    if row_loc is None:\n",
    "        row_loc = tab_loc.find_one(\n",
    "            query_county=x[\"county\"],\n",
    "            query_city=x[\"orig_city\"],\n",
    "            query_address=x[\"address\"],\n",
    "            **x_query\n",
    "        )\n",
    "        if row_loc is None:\n",
    "            row_loc = tab_loc.find_one(\n",
    "                query_county=x[\"orig_county\"],\n",
    "                query_city=x[\"city\"],\n",
    "                query_address=x[\"address\"],\n",
    "                **x_query\n",
    "            )\n",
    "            if row_loc is None:\n",
    "                row_loc = tab_loc.find_one(\n",
    "                    query_county=x[\"county\"],\n",
    "                    query_city=x[\"city\"],\n",
    "                    query_address=x[\"address\"],\n",
    "                    **x_query\n",
    "                )\n",
    "                if row_loc is None:\n",
    "                    print(x)\n",
    "                    print(x_query)\n",
    "                    continue\n",
    "    row_loc_geo = {\n",
    "        name: row_loc[name]\n",
    "        for name in [\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"postal_code\",\n",
    "            \"street\",\n",
    "            \"house_number\",\n",
    "            \"district\",\n",
    "            \"city\",\n",
    "            \"county\",\n",
    "            \"state\",\n",
    "            \"country\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    if real_lat is not None and real_long is not None:\n",
    "        row_loc_geo[\"latitude\"] = real_lat\n",
    "        row_loc_geo[\"longitude\"] = real_long\n",
    "        print(\"added again!\")\n",
    "        print(x)\n",
    "\n",
    "    merged = {**x, **row_loc_geo}\n",
    "    tab_incidents.update(merged, [\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using the final output locations of the incidents because we actually manupulated / discared some locations (if there already had a geolocation)\n",
    "final_loc = list(\n",
    "    tab_incidents.distinct(\n",
    "        *[\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"postal_code\",\n",
    "            \"street\",\n",
    "            \"house_number\",\n",
    "            \"district\",\n",
    "            \"city\",\n",
    "            \"county\",\n",
    "            \"state\",\n",
    "            \"country\",\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_loc.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab_loc_final = db['locations_final']\n",
    "tab_loc.insert_many(final_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(tab_loc.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}